\begin{logos}
This entire high-dimensional trajectory through a space that has real geometric structure, real basins and ridges and gradients, is not something separate from the physical process, not an emergent epiphenomenon floating mysteriously above the neural dynamics, but rather is identical to the intrinsic cause-effect structure itself, the view from inside of what these causal relations feel like when you are those causal relations, when there is no homunculus sitting somewhere else observing the process but only the process itself, recursively modeling its own modeling, predicting its own predictions.
\end{logos}

%==============================================================================
\section{The Hard Problem and Its Dissolution}
%==============================================================================

\begin{connection}
This section engages with the central debates in philosophy of mind:
\begin{itemize}
\item \textbf{Chalmers' Hard Problem} (1995): The explanatory gap between physical processes and phenomenal experience. I think this gap results from a category error, not a genuine ontological divide.
\item \textbf{Nagel's ``What Is It Like''} (1974): The subjective character of experience. I'll formalize this as intrinsic cause-effect structure---what the system is \emph{for itself}.
\item \textbf{Jackson's Knowledge Argument} (1982): Mary the colorblind scientist. My reinterpretation: Mary gains \emph{access to a new scale of description}, not new facts about the same scale.
\item \textbf{Eliminativism} (Churchland, 1981; Dennett, 1991): Consciousness as illusion. I reject this---the illusion would itself be experiential, hence self-refuting.
\item \textbf{Panpsychism} (Chalmers, 2015; Goff, 2017): Experience as fundamental. I accept a version: cause-effect structure at any scale that takes/makes differences has a form of ``being like.''
\end{itemize}
\end{connection}

\subsection{The Standard Formulation}

The ``hard problem'' of consciousness asks: given a complete physical description of a system, why is there something it is like to be that system? How does experience arise from non-experience?

Formally, let $\mathcal{D}^{\text{phys}}$ be a complete physical description of a system---its particles, fields, dynamics, everything describable in third-person terms. The hard problem asserts:
\begin{equation}
\mathcal{D}^{\text{phys}} \not\Rightarrow \mathcal{D}^{\text{phen}}
\end{equation}
where $\mathcal{D}^{\text{phen}}$ is a description of the system's phenomenal properties (what it's like to be it). The claim is that no amount of physical information logically entails phenomenal information.

This formulation rests on a crucial assumption:

\begin{axiom}[Privileged Base Layer---REJECTED]
\label{ax:base}
Physics constitutes a privileged ontological base layer. All other descriptions (chemical, biological, psychological, phenomenal) are ``higher-level'' and must reduce to or supervene on the physical description. What is ``really real'' is what physics describes.
\end{axiom}

I reject this axiom.

\subsection{Ontological Democracy}

Consider the standard reductionist hierarchy:
\begin{center}
\begin{tikzpicture}[
    node distance=0.45cm,
    box/.style={rectangle, draw, rounded corners, minimum width=4cm, minimum height=0.45cm, align=center, font=\small}
]
% Top-down gradient: violet (mind) to red (physics) to gray (unknown)
\node[box, fill=violet!15, draw=violet!60!black] (phenom) {Phenomenal};
\node[box, fill=blue!15, draw=blue!60!black, below=of phenom] (psych) {Psychological};
\node[box, fill=cyan!15, draw=cyan!60!black, below=of psych] (bio) {Biological};
\node[box, fill=green!15, draw=green!60!black, below=of bio] (chem) {Chemical};
\node[box, fill=yellow!15, draw=yellow!60!black, below=of chem] (atom) {Atomic};
\node[box, fill=orange!15, draw=orange!60!black, below=of atom] (subatom) {Subatomic};
\node[box, fill=red!15, draw=red!60!black, below=of subatom] (qft) {Quantum Fields};
\node[box, fill=gray!20, draw=gray!60!black, below=of qft] (base) {\textbf{???}};

\draw[-{Stealth}, thick, gray] (phenom) -- (psych) node[midway, right, font=\footnotesize, text=gray!70!black] {reduces?};
\draw[-{Stealth}, thick, gray] (psych) -- (bio);
\draw[-{Stealth}, thick, gray] (bio) -- (chem);
\draw[-{Stealth}, thick, gray] (chem) -- (atom);
\draw[-{Stealth}, thick, gray] (atom) -- (subatom);
\draw[-{Stealth}, thick, gray] (subatom) -- (qft);
\draw[-{Stealth}, thick, gray, dashed] (qft) -- (base);

% Brace on left indicating "equally real"
\draw[decorate, decoration={brace, amplitude=8pt, mirror}, thick, gray!60]
    ([xshift=-0.3cm]phenom.north west) -- ([xshift=-0.3cm]qft.south west)
    node[midway, left=0.4cm, font=\scriptsize, text=gray, align=center, rotate=90] {equally real?};
\end{tikzpicture}
\end{center}

At each level, one might claim the higher level ``reduces to'' the lower. But the regression terminates in uncertainty:
\begin{itemize}
\item Wave functions are descriptions of probability distributions
\item Probability amplitudes describe which interactions are more or less likely
\item What ``actually happens'' when a measurement occurs is deeply contested
\item Below quantum fields, we have no clear ontology at all
\end{itemize}

The supposed ``base layer'' turns out to be:
\begin{enumerate}
\item Probabilistic, not deterministic
\item Descriptive, not fundamental (wave functions are representations)
\item Incomplete (we don't know what underlies field interactions)
\item Not clearly more ``real'' than any other scale of description
\end{enumerate}

\begin{definition}[Ontological Democracy]
Every scale of structural organization with its own causal closure is \emph{equally real} at that scale. No layer is privileged as ``the'' fundamental reality. Each layer:
\begin{enumerate}[label=(\alph*)]
\item Has its own causal structure
\item Has its own dynamics and laws
\item Exerts influence on adjacent layers (both ``up'' and ``down'')
\item Is incomplete as a description of the whole
\item Is sufficient for phenomena at its scale
\end{enumerate}
\end{definition}

\begin{proposition}[No Reduction Required]
Under ontological democracy, the demand that phenomenal properties ``reduce to'' physical properties is ill-posed. Chemistry doesn't reduce to physics in a way that eliminates chemical causation---chemical causation is real at the chemical scale. Similarly, phenomenal properties don't need to reduce to physical properties---they are real at the phenomenal scale.
\end{proposition}

\subsection{Existence as Causal Participation}

We need a criterion for existence that applies uniformly across scales---here "we" means anyone trying to think clearly about this.

\begin{definition}[Causal Existence]
An entity $X$ \emph{exists} at scale $\sigma$ if and only if:
\begin{equation}
\exists Y: \MI(X; Y | \text{background}_\sigma) > 0
\end{equation}
That is, $X$ takes and makes differences at scale $\sigma$. It participates in causal relations at that scale.
\end{definition}

\begin{example}
\begin{itemize}
\item An electron exists at the quantum scale: it takes differences (responds to fields) and makes differences (affects measurements).
\item A cell exists at the biological scale: it takes differences (nutrients, signals) and makes differences (metabolism, division, death).
\item An experience exists at the phenomenal scale: it takes differences (sensory input, memory) and makes differences (attention, behavior, learning).
\end{itemize}
\end{example}

This is closely aligned with IIT's foundational axiom: to exist is to have cause-effect power. But we extend it: cause-effect power at any scale constitutes existence at that scale, with no scale privileged.

\subsection{The Dissolution}

The hard problem asked: how do you get experience from non-experience? The answer is: \textit{you don't need to}.

Just as chemistry doesn't emerge from non-chemistry---you have chemistry when you have the right causal organization at the chemical scale---experience doesn't emerge from non-experience. You have experience when you have the right causal organization at the experiential scale.

The question ``why is there something it's like to be this system?'' is exactly as deep as ``why does chemistry exist?'' or ``why are there quantum fields?'' I don't know why there's anything at all (idk if anybody does). But given that there's anything, the emergence of self-modeling systems with integrated cause-effect structure is not mysterious---it's typical.

\begin{keyresult}
The hard problem dissolves not because we answered it, but because we showed it was asking for a privilege (reduction to physics) that physics itself doesn't have.
\end{keyresult}

%==============================================================================
\section{The Identity Thesis}
%==============================================================================

\begin{connection}
The identity thesis is a formalization of \textbf{Integrated Information Theory (IIT)} developed by Giulio Tononi and collaborators (2004--present):
\begin{itemize}
\item \textbf{IIT 1.0} (Tononi, 2004): Introduced $\Phi$ as a measure of integrated information
\item \textbf{IIT 2.0} (Balduzzi \& Tononi, 2008): Added the concept of ``qualia space''
\item \textbf{IIT 3.0} (Oizumi, Albantakis \& Tononi, 2014): Full axiom/postulate structure; introduced cause-effect structure
\item \textbf{IIT 4.0} (Albantakis et al., 2023): Refined integration measures, introduced intrinsic difference
\end{itemize}

Key IIT axioms that we adopt:
\begin{enumerate}
\item \textbf{Intrinsicality}: Experience exists for itself, not for an external observer
\item \textbf{Information}: Experience is specific---this experience and no other
\item \textbf{Integration}: Experience is unified and irreducible
\item \textbf{Exclusion}: Experience has definite boundaries
\item \textbf{Composition}: Experience is structured
\end{enumerate}

My contribution here is connecting IIT's structural characterization to (1) the thermodynamic ladder, (2) the viability manifold, and (3) operational measures for artificial systems.
\end{connection}

\subsection{Statement of the Thesis}

\begin{hypothesis}[Identity Thesis]
Phenomenal experience \textit{is} intrinsic cause-effect structure. Not caused by it, not correlated with it, but identical to it. The phenomenal properties of an experience (what it's like) just are the structural properties of the system's internal causal relations, described from the intrinsic perspective.
\end{hypothesis}

More formally:

\begin{definition}[Cause-Effect Structure]
For a system $\mathcal{S}$ in state $\state$, the cause-effect structure $\cestructure(\mathcal{S}, \state)$ is the complete specification of:
\begin{enumerate}[label=(\alph*)]
\item All distinctions $\{\distinction_i\}$: subsets of the system's elements in their current states
\item The cause repertoire of each distinction: $p(\text{past} | \distinction_i)$
\item The effect repertoire of each distinction: $p(\text{future} | \distinction_i)$
\item All relations $\{\relation_{ij}\}$: overlaps and connections between distinctions' causes/effects
\item The irreducibility of each distinction and relation
\end{enumerate}
\end{definition}

\begin{definition}[Intrinsic Perspective]
The \emph{intrinsic perspective} of a system is the description of its cause-effect structure without reference to any external observer, coordinate system, or comparison class. It is the structure as it exists for the system itself.
\end{definition}

\begin{axiom}[IIT Identity]
\begin{equation}
\phenom(\mathcal{S}, \state) \equiv \cestructure^{\text{intrinsic}}(\mathcal{S}, \state)
\end{equation}
The phenomenal structure $\phenom$ is identical to the intrinsic cause-effect structure $\cestructure$.
\end{axiom}

This is not a correlation claim or a supervenience claim. It is an identity claim, analogous to:
\begin{equation}
\text{Water} \equiv \text{H}_2\text{O}
\end{equation}

\subsection{Implications for the Zombie Argument}

The philosophical zombie is supposed to be conceivable: a system physically/functionally identical to a conscious being but lacking experience. If conceivable, experience isn't necessitated by physical structure.

\begin{theorem}[Zombie Inconceivability]
Under the identity thesis, philosophical zombies are not coherently conceivable. A system with the relevant cause-effect structure \textit{is} an experience; there is no further fact about whether it ``really'' has phenomenal properties.
\end{theorem}

\begin{proof}
By the identity thesis, $\phenom \equiv \cestructure^{\text{intrinsic}}$. To conceive a zombie is to conceive a system with $\cestructure^{\text{intrinsic}}$ but without $\phenom$. But since these are identical, this is like conceiving of water without H$_2$O---not genuinely conceivable once the identity is understood.
\end{proof}

\subsection{The Structure of Experience}

If experience is cause-effect structure, then the \textit{kind} of experience is determined by the \textit{shape} of that structure. Different phenomenal properties correspond to different structural features.

IIT proposes that the essential properties of any experience are:

\begin{enumerate}
\item \textbf{Intrinsicality}: The experience exists for the system itself, not relative to an external observer.
\item \textbf{Information}: The experience is specific---this experience, not any other possible one.
\item \textbf{Integration}: The experience is unified---it cannot be decomposed into independent sub-experiences.
\item \textbf{Exclusion}: The experience has definite boundaries---there is a fact about what is and isn't part of it.
\item \textbf{Composition}: The experience is structured---composed of distinctions and relations among them.
\end{enumerate}

These are translated into physical/structural postulates:
\begin{itemize}
\item Intrinsicality $\to$ Cause-effect power within the system
\item Information $\to$ Specific cause-effect repertoires
\item Integration $\to$ Irreducibility to partitioned components
\item Exclusion $\to$ Maximality of the integrated complex
\item Composition $\to$ The full structure of distinctions and relations
\end{itemize}

%==============================================================================
\section{The Geometry of Affect}
%==============================================================================

\begin{connection}
My geometric theory of affect builds on and extends established dimensional models:
\begin{itemize}
\item \textbf{Russell's Circumplex Model} (1980): Two-dimensional (valence $\times$ arousal) organization of affect. I extend this with additional structural dimensions (integration, effective rank, counterfactual weight, self-model salience) invoked as needed.
\item \textbf{Watson \& Tellegen's PANAS} (1988): Positive/Negative Affect Schedule. My valence dimension corresponds to their hedonic axis.
\item \textbf{Scherer's Component Process Model} (2009): Emotions as synchronized changes across subsystems. My integration measure $\intinfo$ captures this synchronization.
\item \textbf{Barrett's Constructed Emotion Theory} (2017): Emotions as constructed from core affect + conceptual knowledge. My framework specifies the \emph{structural} basis of the construction.
\item \textbf{Damasio's Somatic Marker Hypothesis} (1994): Body states guide decision-making. My valence definition (gradient on viability manifold) is the mathematical formalization.
\end{itemize}
\end{connection}

\begin{sidebar}[title=On Dimensionality]
I'm not claiming that six dimensions are necessary or sufficient for characterizing all affect. These are a \emph{useful} coordinate system, not \emph{the} coordinate system. Just as Cartesian coordinates serve some problems and polar coordinates serve others, these dimensions are tools for thought, not discoveries of essence. Different phenomena may require different subsets:
\begin{itemize}
\item Some affects are essentially \textbf{two-dimensional} (valence + arousal suffices for basic mood)
\item Others require \textbf{self-referential structure} (shame requires high $\mathcal{SM}$; flow requires low $\mathcal{SM}$)
\item Still others are defined by \textbf{temporal structure} (grief requires persistent counterfactual coupling to the lost object)
\item Some may require dimensions not in this list (anger requires ``other-model compression'')
\end{itemize}
The dimensions below form a \emph{toolkit}---structural features that may or may not matter for any given phenomenon. Empirical investigation may reveal that some proposed dimensions are redundant, or that additional dimensions are needed. I'll invoke only what is necessary.
\end{sidebar}

\subsection{Affects as Structural Motifs}

If different experiences correspond to different structures, then \textit{affects}---the qualitative character of emotional/valenced states---should correspond to particular structural motifs: characteristic patterns in the cause-effect geometry.

\begin{definition}[Affect Space]
The \emph{affect space} $\mathcal{A}$ is a geometric space whose points correspond to possible qualitative states. Rather than fixing a universal dimensionality, we identify the structural features that define each affect---features without which that affect would not be that affect.
\end{definition}

The following structural measures form a toolkit for characterizing affect. Not all are relevant to every phenomenon; I invoke each only when it does essential work:

\begin{description}
\item[Valence ($\valence$)] Gradient alignment on the viability manifold. Nearly universal---most affects have valence.
\item[Arousal ($\arousal$)] Rate of belief/state update. Distinguishes activated from quiescent states.
\item[Integration ($\intinfo$)] Irreducibility of cause-effect structure. Constitutive for unified vs.\ fragmented experience.
\item[Effective Rank ($\effrank$)] Distribution of active degrees of freedom. Constitutive when the contrast between expansive and collapsed experience matters.
\item[Counterfactual Weight ($\mathcal{CF}$)] Resources allocated to non-actual trajectories. Constitutive for affects defined by temporal orientation (anticipation, regret, planning).
\item[Self-Model Salience ($\mathcal{SM}$)] Degree of self-focus in processing. Constitutive for self-conscious emotions and their opposites (absorption, flow).
\end{description}

\subsection{Valence: Gradient Alignment}

\begin{definition}[Valence]
Let $\viable$ be the system's viability manifold and let $\mathbf{x}_t$ be the current state. Let $\hat{\mathbf{x}}_{t+1:t+H}$ be the predicted trajectory under current policy. Define:
\begin{equation}
\valence_t = -\frac{1}{H} \sum_{k=1}^{H} \gamma^k \nabla_{\mathbf{x}} d(\mathbf{x}, \partial\viable) \bigg|_{\hat{\mathbf{x}}_{t+k}} \cdot \frac{d\hat{\mathbf{x}}_{t+k}}{dt}
\end{equation}
where $d(\cdot, \partial\viable)$ is the distance to the viability boundary. Positive valence means the predicted trajectory moves into the viable interior; negative valence means it approaches the boundary.
\end{definition}

Alternatively, in RL terms:

\begin{definition}[Valence (RL formulation)]
\begin{equation}
\valence_t = \E_{\policy}\left[ A^{\policy}(\state_t, \action_t) \right] = \E_{\policy}\left[ Q^{\policy}(\state_t, \action_t) - V^{\policy}(\state_t) \right]
\end{equation}
The expected advantage of the current action: how much better (or worse) is this action than the average action from this state?
\end{definition}

\begin{definition}[Valence Dynamics]
The rate of change of integrated information along the trajectory:
\begin{equation}
\dot{\valence}_t = \frac{d\intinfo}{dt}\bigg|_{\hat{\mathbf{x}}_{t:t+H}}
\end{equation}
Positive $\dot{\valence}$ indicates expanding structure; negative indicates contraction.
\end{definition}

\begin{phenomenal}
\textbf{Positive valence} corresponds to trajectories descending the free-energy landscape, expanding affordances, moving toward sustainable states. \\
\textbf{Negative valence} corresponds to trajectories ascending toward constraint violation, contracting possibilities.
\end{phenomenal}

\begin{sidebar}[title=Valence in Discrete Substrate]
In a cellular automaton or other discrete dynamical system, valence becomes exactly computable:
\begin{itemize}
\item $\viable$ = configurations where the pattern persists
\item $\partial\viable$ = configurations where the pattern dissolves
\item $d(\mathbf{x}, \partial\viable)$ = minimum Hamming distance to a non-viable state
\item Trajectory = sequence of configurations $\mathbf{x}_1, \mathbf{x}_2, \ldots$
\end{itemize}
Then:
\begin{equation}
\valence_t = d(\mathbf{x}_{t+1}, \partial\viable) - d(\mathbf{x}_t, \partial\viable)
\end{equation}
Positive when the pattern moves away from dissolution; negative when approaching it; zero when maintaining constant distance. For a glider cruising through empty space: $\valence \approx 0$. For a glider approaching collision: $\valence < 0$. For a pattern that just escaped a near-collision: $\valence > 0$.

This is not metaphor---it is the viability gradient formalized for discrete state spaces.
\end{sidebar}

\subsection{Arousal: Update Rate}

\begin{definition}[Arousal]
\begin{equation}
\arousal_t = \KL\left( \belief_{t+1} \| \belief_t \right) = \sum_{\mathbf{x}} \belief_{t+1}(\mathbf{x}) \log \frac{\belief_{t+1}(\mathbf{x})}{\belief_t(\mathbf{x})}
\end{equation}
The KL divergence between successive belief states measures how much the system's world model is being updated.
\end{definition}

In latent-space models:
\begin{equation}
\arousal_t = \| \latent_{t+1} - \latent_t \|^2 \quad \text{or} \quad \MI(\obs_t; \latent_{t+1} | \latent_t, \action_t)
\end{equation}

\begin{phenomenal}
\textbf{High arousal}: Large belief updates, far from any attractor, system actively navigating. \\
\textbf{Low arousal}: Near a fixed point, low surprise, system at rest in a basin.
\end{phenomenal}

\subsection{Integration: Irreducibility}

As defined in Part I:
\begin{equation}
\intinfo(\state) = \min_{\text{partitions } P} D\left[ p(\state_{t+1} | \state_t) \| \prod_{p \in P} p(\state^p_{t+1} | \state^p_t) \right]
\end{equation}

Or using proxies:
\begin{equation}
\intinfo_{\text{proxy}} = \Delta_P = \mathcal{L}_{\text{pred}}[\text{partitioned}] - \mathcal{L}_{\text{pred}}[\text{full}]
\end{equation}

\begin{phenomenal}
\textbf{High integration}: The experience is unified; its parts cannot be separated without loss. \\
\textbf{Low integration}: The experience is fragmentary or modular.
\end{phenomenal}

\begin{sidebar}[title=Integration in Discrete Substrate]
In a cellular automaton, $\intinfo$ is directly computable for small patterns:
\begin{enumerate}
\item Define the pattern as cells $\{c_1, c_2, \ldots, c_n\}$
\item For each bipartition $P = (A, B)$:
\begin{itemize}
\item Compute $p(\state_{t+1} | \state_t)$ for the whole pattern
\item Compute $p_A(\state^A_{t+1} | \state^A_t) \times p_B(\state^B_{t+1} | \state^B_t)$ for independent parts
\item Measure divergence $D[p \| p_A \times p_B]$
\end{itemize}
\item $\intinfo = \min_P D$
\end{enumerate}
High $\intinfo$ means you cannot partition the pattern without losing predictive power. The parts must be considered together.

For a simple glider: $\intinfo$ is probably modest (only 5 cells). For a complex pattern with tightly coupled components: $\intinfo$ can be high. The key empirical question: does high $\intinfo$ correlate with survival, behavioral complexity, or adaptive response to perturbation?
\end{sidebar}

\subsection{Effective Rank: Concentration vs. Distribution}

\begin{definition}[Effective Rank]
For state covariance $C$:
\begin{equation}
\effrank = \frac{(\tr C)^2}{\tr(C^2)} = \frac{\left(\sum_i \lambda_i\right)^2}{\sum_i \lambda_i^2}
\end{equation}
\end{definition}

\begin{proposition}[Rank Interpretation]
\begin{itemize}
\item $\effrank \approx 1$: All variance concentrated in one dimension (maximally collapsed)
\item $\effrank \approx n$: Variance uniformly distributed (maximally expanded)
\end{itemize}
\end{proposition}

\begin{phenomenal}
\textbf{High rank}: Many degrees of freedom active; distributed, expansive experience. \\
\textbf{Low rank}: Collapsed into narrow subspace; concentrated, focused, or trapped experience.
\end{phenomenal}

\begin{sidebar}[title=Effective Rank in Discrete Substrate]
For a pattern in a CA, record its trajectory $\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_T$ (configuration at each timestep). Each configuration is a point in $\{0,1\}^n$. Compute the covariance matrix $C$ of these binary vectors treated as $\R^n$ points.

For a glider: the trajectory lies on a low-dimensional manifold (position $\times$ position $\times$ phase $\approx 3$--$4$ effective dimensions out of $n$ cells). $\effrank$ is small.

For a complex evolving pattern: the trajectory may explore many independent dimensions. $\effrank$ is large.

The thesis predicts this maps to phenomenology:
\begin{itemize}
\item Joy: high $\effrank$ (expansive, many active possibilities)
\item Suffering: low $\effrank$ (collapsed, trapped in narrow manifold)
\end{itemize}
In discrete substrate, this is not metaphor but measurement.
\end{sidebar}

\subsection{Counterfactual Weight}

\begin{definition}[Counterfactual Weight]
Let $\mathcal{R}$ be the set of imagined rollouts (counterfactual trajectories) and $\mathcal{P}$ be present-state processing. Define:
\begin{equation}
\mathcal{CF}_t = \frac{\text{Compute}_t(\mathcal{R})}{\text{Compute}_t(\mathcal{R}) + \text{Compute}_t(\mathcal{P})}
\end{equation}
The fraction of computational resources devoted to modeling non-actual possibilities.
\end{definition}

In model-based RL:
\begin{equation}
\mathcal{CF}_t = \sum_{\tau \in \text{rollouts}} w(\tau) \cdot \entropy[\tau] \quad \text{where} \quad w(\tau) \propto |V(\tau)|
\end{equation}
Rollouts weighted by their value magnitude and diversity.

\begin{phenomenal}
\textbf{High counterfactual weight}: Mind is elsewhere---planning, worrying, fantasizing, anticipating. \\
\textbf{Low counterfactual weight}: Present-focused, reactive, in-the-moment.
\end{phenomenal}

\begin{sidebar}[title=Counterfactual Weight in Discrete Substrate]
For most CA patterns: $\mathcal{CF} = 0$. They follow their dynamics without simulation.

But Life contains universal computers---patterns that can simulate arbitrary computations, including Life itself. Imagine a pattern $\mathcal{B}$ containing:
\begin{itemize}
\item A simulator subregion that runs a model of possible futures
\item A controller that adjusts behavior based on simulator output
\end{itemize}
Then:
\begin{equation}
\mathcal{CF} = \frac{|\text{simulator cells}|}{|\mathcal{B}|}
\end{equation}
The fraction of the pattern devoted to counterfactual reasoning.

Such patterns are rare and complex---universal computation requires many cells. But they should outperform simple patterns: they can anticipate threats (fear structure) and identify opportunities (desire structure). The prediction: patterns with $\mathcal{CF} > 0$ survive longer in hostile environments.
\end{sidebar}

\subsection{Self-Model Salience}

\begin{definition}[Self-Model Salience]
\begin{equation}
\mathcal{SM}_t = \MI(\latent^{\text{self}}_t; \action_t) / \entropy(\action_t)
\end{equation}
The fraction of action entropy explained by the self-model component.
\end{definition}

Alternatively:
\begin{equation}
\mathcal{SM}_t = \frac{\text{dim}(\latent^{\text{self}})}{\text{dim}(\latent^{\text{total}})} \cdot \text{activity}(\latent^{\text{self}}_t)
\end{equation}

\begin{phenomenal}
\textbf{High self-salience}: Self-focused, self-conscious, self as primary object of attention. \\
\textbf{Low self-salience}: Self-forgotten, absorbed in environment or task.
\end{phenomenal}

\begin{sidebar}[title=Self-Model Salience in Discrete Substrate]
In a CA, a pattern's ``behavior'' is its evolution. Let $\latent^{\text{self}}$ denote cells that track the pattern's own state (the self-model region). Then:
\begin{equation}
\mathcal{SM} = \frac{\MI(\latent^{\text{self}}_t; \state_{t+1})}{\entropy(\state_{t+1})}
\end{equation}
High $\mathcal{SM}$: the pattern's evolution is dominated by self-monitoring. Changes in self-model strongly predict what happens.

Low $\mathcal{SM}$: external factors dominate; the self-model exists but doesn't influence much.

The thesis predicts: self-conscious states (shame, pride) have high $\mathcal{SM}$; absorption states (flow) have low $\mathcal{SM}$. In CA terms, a pattern ``in flow'' has its self-tracking cells decoupled from its core dynamics---it acts without monitoring.
\end{sidebar}

\begin{sidebar}[title=Self-Model Scope in Discrete Substrate]
Beyond salience, there is \emph{scope}: what does the self-model include?

In a CA, consider two gliders that have become ``coupled''---their trajectories mutually dependent. Each glider's self-model could have:
\begin{itemize}
\item $\theta_{\text{narrow}}$: Self-model includes only this glider. $\viable = \{\text{configs where THIS pattern persists}\}$.
\item $\theta_{\text{expanded}}$: Self-model includes both. $\viable = \{\text{configs where BOTH persist}\}$.
\end{itemize}
Observable difference: with narrow scope, a glider might sacrifice the other to save itself. With expanded scope, it might sacrifice itself to save the pair.

The key question: can scope expansion emerge dynamically? Can patterns that start with narrow scope ``learn'' to identify with larger structures? This would be the discrete-substrate analogue of the identification expansion discussed in the epilogue---$\viable(S(\theta))$ genuinely reshaped by expanding $\theta$.
\end{sidebar}

\begin{sidebar}[title=Salience vs. Scope]
Self-model salience ($\mathcal{SM}$) measures how much attention the self-model receives---how prominent self-reference is in current processing. But there is another parameter: self-model \emph{scope}---what the self-model includes.

Let $S(\theta)$ denote the self-model parameterized by its boundary scope $\theta$. Let $\viable(S)$ denote the viability manifold induced by self-model $S$. Then:
\begin{itemize}
\item $\theta_{\text{narrow}}$: $S$ includes only this biological trajectory $\Rightarrow$ $\partial\viable$ is located at biological death $\Rightarrow$ persistent negative gradient
\item $\theta_{\text{expanded}}$: $S$ includes patterns persisting beyond biological death $\Rightarrow$ $\partial\viable$ recedes $\Rightarrow$ gradient can be positive even as death approaches
\end{itemize}

This is not metaphor. If the viability manifold is defined by what the system is trying to preserve, and if what the system is trying to preserve is determined by its self-model, then self-model scope directly shapes $\viable(S(\theta))$. Expanding identification genuinely reshapes the existential gradient.

Salience and scope interact: high salience with narrow scope produces existential anxiety (trapped in awareness of bounded self approaching boundary). High salience with expanded scope produces something closer to what contemplatives describe as ``witnessing''---self-aware but identified with something that doesn't end where the body ends.
\end{sidebar}

%==============================================================================
\section{Affect Motifs}
%==============================================================================

Let's now characterize specific affects as structural motifs, invoking only the dimensions that define each. Before formalizing these structures, we ground each in its phenomenal character---the felt texture that any adequate theory must explain.

\textbf{Joy} \textit{expands}. It is \textit{light} before it is anything else---buoyant, effervescent, the body forgetting its weight. The world opens; possibilities \textit{multiply}; the \textit{self recedes} because it need not defend. Joy is surplus: more paths than required, more resources than consumed, \textit{slack} in every direction.

Where joy opens, \textbf{suffering} \textit{crushes}. It \textit{compresses} the world to a single unbearable point and makes that point more \textit{vivid} than anything has ever been. This is the paradox: suffering is hyper-real, more present than presence, more \textit{unified} than unity. You cannot look away. You cannot \textit{decompose} it. You are \textit{trapped} in a cage made of your own \textit{integration}.

\textbf{Fear} throws the self forward into \textit{futures} that threaten to annihilate it---cold, sharp, electric with \textit{anticipation}. The body readies before the mind has finished computing. Time dilates around the approaching harm. Fear is suffering that hasn't arrived yet, and the \textit{not-yet} is where we live.

We say \textbf{anger} is \textit{hot}, and we are not speaking metaphorically. Anger \textit{externalizes}: it \textit{simplifies} the world into self-versus-obstacle and energizes removal. Watch what happens to your model of the other person when you are angry---it \textit{flattens}, becomes a caricature, loses \textit{dimensionality}. Complexity collapses into opposition. This is why anger feels powerful and also stupid: you are burning \textit{integration} on a cartoon.

\textbf{Desire} \textit{funnels}. The world reorganizes around an \textit{attractor} not yet reached---magnetic, urgent, all-consuming. Everything becomes instrumental; the goal \textit{saturates} attention. Desire is joy's \textit{gradient}, pointing toward the basin but not yet in it. This is why anticipation often exceeds consummation: the structure of \textit{approach} is tighter than the structure of \textit{arrival}.

\textbf{Curiosity} \textit{reaches} outward---but unlike fear, it reaches toward \textit{promise} rather than threat. Pulling, open, playful. The \textit{uncertainty} that makes fear contract makes curiosity \textit{expand}. Same high counterfactual weight, opposite \textit{valence}. The difference is whether the \textit{branches} lead somewhere you want to go.

And \textbf{grief}? Grief \textit{persists}. Hollow, aching, curiously timeless. The lost object remains \textit{woven into} every prediction; every expectation that included them \textit{fails} silently, over and over. The world has changed. The \textit{model} has not caught up. Grief is the metabolic cost of love's \textit{integration}.

\vspace{0.5em}
\noindent What follows formalizes these textures as geometry.

\subsection{Joy}

\begin{definition}[Joy Motif]
Joy requires four dimensions:
\begin{itemize}
\item $\valence > 0$ (positive gradient on viability manifold)
\item $\intinfo$ high (unified, coherent experience)
\item $\effrank$ high (many degrees of freedom active---expansiveness)
\item $\mathcal{SM}$ low (self recedes; no need to defend)
\end{itemize}
Arousal varies (joy can be calm or excited). Counterfactual weight is incidental.
\end{definition}

\textbf{Structural interpretation}: The cause-effect structure has the shape of ``abundance''---multiple paths to good outcomes, redundancy, slack in the system. Many distinctions active simultaneously ($\effrank$ high), tightly coupled ($\intinfo$ high), but the self is light because the world is cooperating ($\mathcal{SM}$ low). This is why joy \emph{expands}: the geometry literally has more active dimensions.

\subsection{Suffering}

\begin{definition}[Suffering Motif]
Suffering requires three dimensions:
\begin{itemize}
\item $\valence < 0$ (negative gradient---approaching viability boundary)
\item $\intinfo$ high (hyper-unified, impossible to decompose or look away)
\item $\effrank$ low (collapsed into narrow subspace---trapped)
\end{itemize}
This is the core structural signature. Self-model salience is often high (the self as locus of the problem), but not necessarily---one can suffer while absorbed in external pain.
\end{definition}

\textbf{Structural interpretation}: High integration but collapsed into low-rank subspace. The system is deeply coupled but constrained to a dominant attractor it cannot escape.

\begin{keyresult}
The $\intinfo$-$\effrank$ dissociation is the key insight: suffering feels \textit{more real} than neutral states because it is actually more integrated. But it feels \textit{trapped} because the integration is constrained to a narrow manifold.

Formally: $\intinfo_{\text{suffering}} > \intinfo_{\text{neutral}}$ but $\effrank_{\text{suffering}} \ll \effrank_{\text{neutral}}$.

This is why you cannot simply ``think your way out'' of suffering---the very integration that makes it vivid also makes it inescapable.
\end{keyresult}

\subsection{Fear}

\begin{definition}[Fear Motif]
Fear is defined by three dimensions:
\begin{itemize}
\item $\valence < 0$ (anticipated negative gradient)
\item $\mathcal{CF}$ high, concentrated on threat trajectories (the not-yet dominates)
\item $\mathcal{SM}$ high (self foregrounded as the thing-that-might-be-harmed)
\end{itemize}
Arousal is typically high but not defining---cold fear exists. Integration and rank vary.
\end{definition}

\textbf{Structural interpretation}: Fear is suffering projected into the future. The temporal structure ($\mathcal{CF}$) is essential: fear lives in anticipation. The self-model must be salient because fear is fundamentally about threat \emph{to the self}. Remove the counterfactual weight (make it present-focused) and you get suffering. Remove the self-salience (make it about external objects) and you get something closer to aversion or disgust.

\subsection{Anger}

\begin{definition}[Anger Motif]
Anger requires valence, arousal, plus a feature not in the standard toolkit---\emph{other-model compression}:
\begin{itemize}
\item $\valence < 0$ (obstacle to viability)
\item $\arousal$ high (energized, mobilized for action)
\item $\text{dim}(\text{other-model}) \ll \text{dim}(\text{other-model})_{\text{normal}}$ (the other becomes a caricature)
\item Externalized causal attribution (the problem is \emph{out there})
\end{itemize}
\end{definition}

\textbf{Structural interpretation}: Anger simplifies. The other-model collapses into a low-dimensional obstacle-representation. Self-model may be complex, but the \emph{other} becomes flat, predictable, opposable. This is why anger feels powerful and stupid simultaneously: you're burning cognitive resources on a cartoon.

Note that other-model compression is not one of my standard dimensions---it emerges as essential for anger specifically. This illustrates the toolkit approach: I invoke whatever structural features do the work.

\subsection{Desire/Lust}

\begin{definition}[Desire Motif]
Desire is defined by anticipated valence, counterfactual weight, and a structural feature---\emph{goal-funneling}:
\begin{itemize}
\item $\valence > 0$ but projected forward (anticipated positive gradient)
\item $\mathcal{CF}$ high, concentrated on approach trajectories
\item Goal-funneling: many dimensions of experience converge toward narrow outcome space
\end{itemize}
Arousal is typically high but not definitional---one can desire calmly.
\end{definition}

\textbf{Structural interpretation}: Desire is the gradient of joy. The world reorganizes around an attractor not yet reached. Everything becomes instrumental; the goal saturates attention. The ``funneling'' structure---high-dimensional input collapsing toward low-dimensional goal---is what gives desire its characteristic urgency.

\begin{proposition}[Desire vs.\ Joy]
Joy is \textit{at} the attractor; desire is \textit{approaching} it. Structurally:
\begin{equation}
d(\state_{\text{joy}}, \mathcal{A}) \approx 0, \quad d(\state_{\text{desire}}, \mathcal{A}) > 0, \quad \frac{d}{dt}d(\state_{\text{desire}}, \mathcal{A}) < 0
\end{equation}
where $\mathcal{A}$ is the goal attractor. This explains why anticipation often exceeds consummation: the structure of \emph{approach} (funneling, convergent) is tighter than the structure of \emph{arrival} (expansive, slack).
\end{proposition}

\subsection{Curiosity}

\begin{definition}[Curiosity Motif]
Curiosity is essentially two-dimensional:
\begin{itemize}
\item $\valence > 0$ specifically toward uncertainty-reduction (anticipated information gain)
\item $\mathcal{CF}$ high with high entropy over counterfactual outcomes (many branches, not converged on one)
\item Uncertainty is \emph{welcomed}, not aversive
\end{itemize}
Self-model salience is typically low (absorbed in the object of curiosity).
\end{definition}

\textbf{Structural interpretation}: Curiosity and fear share high counterfactual weight---both live in the space of possibilities. The difference is valence orientation: fear's branches lead to threat, curiosity's branches lead to expanded affordances. Same temporal structure, opposite gradient direction.

\begin{proposition}[Curiosity as Intrinsic Motivation]
Curiosity $\approx$ positive valence attached to uncertainty-reduction. Formally:
\begin{equation}
r_{\text{curiosity}} \propto \MI(\obs_{t+1}; \latent | \text{new data}) - \MI(\obs_{t+1}; \latent | \text{old data})
\end{equation}
This is why curiosity feels \emph{pulling}: reducing uncertainty is rewarding.
\end{proposition}

\subsection{Grief}

\begin{definition}[Grief Motif]
Grief requires valence, past-directed counterfactual weight, and two structural features---\emph{persistent coupling to lost object} and \emph{unresolvable prediction error}:
\begin{itemize}
\item $\valence < 0$ (the world is worse than it was)
\item $\mathcal{CF}$ high but directed toward counterfactual \emph{past} (``if only...'')
\item $\MI(\selfmodel; \text{lost-object-model})$ remains high despite the object's absence
\item No action reduces the prediction error---the world has permanently changed
\end{itemize}
Arousal is variable (acute grief is high-arousal; chronic grief may be low).
\end{definition}

\textbf{Structural interpretation}: The lost attachment object remains woven into the self-model and world-model. Predictions involving the lost object continue to be generated and continue to fail. Grief is the metabolic cost of love's integration---the coupling that made the relationship meaningful is precisely what makes its absence painful. The model has not yet updated to the permanent change in the world.

This is why grief takes time: the self-model must be \emph{rewoven} around the absence, and that rewiring is slow.

\subsection{Summary: Defining Dimensions by Affect}

Rather than forcing all affects into a uniform grid, let's summarize each by its defining structure:

\begin{table}[h]
\centering
\small
\begin{tabular}{lp{9cm}}
\toprule
\textbf{Affect} & \textbf{Constitutive Structure} \\
\midrule
Joy & $\valence{+}$, $\intinfo{\uparrow}$, $\effrank{\uparrow}$, $\mathcal{SM}{\downarrow}$ (positive, unified, expansive, self-light) \\
Suffering & $\valence{-}$, $\intinfo{\uparrow}$, $\effrank{\downarrow}$ (negative, hyper-integrated, collapsed) \\
Fear & $\valence{-}$, $\mathcal{CF}{\uparrow}$ (threat-focused), $\mathcal{SM}{\uparrow}$ (anticipatory self-threat) \\
Anger & $\valence{-}$, $\arousal{\uparrow}$, other-model compression (energized, externalized, simplified other) \\
Desire & $\valence{+}$ (anticipated), $\mathcal{CF}{\uparrow}$ (approach), goal-funneling (convergent anticipation) \\
Curiosity & $\valence{+}$ toward uncertainty, $\mathcal{CF}{\uparrow}$ with high branch entropy (welcomed unknown) \\
Grief & $\valence{-}$, $\mathcal{CF}{\uparrow}$ (past-directed), persistent coupling to absent object \\
Shame & $\valence{-}$, $\mathcal{SM}{\uparrow\uparrow}$, integration of negative self-evaluation (self as seen by other) \\
Boredom & $\arousal{\downarrow}$, $\intinfo{\downarrow}$, $\effrank{\downarrow}$ (understimulated, fragmented, collapsed) \\
Awe & $\intinfo$ expanding, $\effrank{\uparrow}$, $\mathcal{SM}{\downarrow}$ (self-dissolution through scale) \\
\bottomrule
\end{tabular}
\caption{Affects characterized by their defining structure. Arrows indicate direction (high/low); different affects require different dimensions.}
\end{table}

Note that different affects require different numbers of dimensions. Boredom is essentially three-dimensional (low arousal, low integration, low rank). Anger requires a structural feature (other-model compression) not in the standard toolkit. This is as it should be: I invoke the geometry that does the work.

\begin{todo_empirical}
\textbf{Quantifying the affect table}: The qualitative descriptors (high, med, low) require empirical calibration:

\textbf{Study 1: Affect induction with neural recording}
\begin{itemize}
\item Induce target affects via validated protocols (film clips, autobiographical recall, IAPS images)
\item Measure integration proxies (transfer entropy density, Lempel-Ziv complexity) from EEG/MEG
\item Measure effective rank from neural state covariance
\item Compare self-report (PANAS, SAM) with structural measures
\end{itemize}

\textbf{Study 2: Real-time affect tracking}
\begin{itemize}
\item Continuous self-report (dial/slider) during naturalistic experience
\item Correlate with physiological proxies (HRV for arousal, pupil for $\mathcal{CF}$, skin conductance)
\item Develop regression model: self-report $\sim f(\text{structural measures})$
\end{itemize}

\textbf{Study 3: Cross-modal validation}
\begin{itemize}
\item Compare fMRI (spatial resolution) with MEG (temporal resolution)
\item Validate effective rank measure across modalities
\item Test whether integration predicts subjective intensity
\end{itemize}

\textbf{Target outputs}: Numerical ranges for each cell, confidence intervals, individual difference parameters.
\end{todo_empirical}

%==============================================================================
\section{Dynamics and Transitions}
%==============================================================================

\subsection{Affect Trajectories}

Affects are not static points but dynamic trajectories through affect space. The evolution can be written:
\begin{equation}
\frac{d\mathbf{a}}{dt} = F(\mathbf{a}, \obs, \action, \text{context}) + \bm{\eta}
\end{equation}
where $\mathbf{a} = (\valence, \arousal, \intinfo, \effrank, \mathcal{CF}, \mathcal{SM})$.

\begin{proposition}[Affect Blending]
Adjacent affects in the space blend into each other continuously:
\begin{itemize}
\item Fear $\to$ Anger as causal attribution externalizes
\item Desire $\to$ Joy as goal distance $\to 0$
\item Suffering $\to$ Curiosity as valence flips while $\mathcal{CF}$ remains high
\item Grief $\to$ Nostalgia as arousal decreases and $\mathcal{CF}_{\text{approach}}$ replaces $\mathcal{CF}_{\text{avoidance}}$
\end{itemize}
\end{proposition}

\subsection{Attractor Dynamics}

Some affect regions are attractors; the system tends to stay in them once entered. Others are transient.

\begin{definition}[Affect Attractor]
An affect region $\mathcal{R} \subset \mathcal{A}$ is an \emph{attractor} if:
\begin{equation}
\prob(\mathbf{a}_{t+\tau} \in \mathcal{R} | \mathbf{a}_t \in \mathcal{R}) > \prob(\mathbf{a}_{t+\tau} \in \mathcal{R} | \mathbf{a}_t \notin \mathcal{R})
\end{equation}
for some characteristic time $\tau$.
\end{definition}

\begin{conjecture}[Pathological Attractors]
Depression, addiction, and chronic anxiety are characterized by pathologically stable attractors in affect space:
\begin{itemize}
\item \textbf{Depression}: Attractor at (low $\valence$, low $\arousal$, high $\intinfo$, low $\effrank$, low $\mathcal{CF}$, high $\mathcal{SM}$)
\item \textbf{Addiction}: Attractor at (high $\valence$ conditional on substance, collapsing $\effrank$ in goal space)
\item \textbf{Anxiety}: Diffuse attractor with (low $\valence$, high $\arousal$, high $\mathcal{CF}$ spread across many threats)
\end{itemize}
\end{conjecture}

%==============================================================================
\section{Novel Predictions}
%==============================================================================

\subsection{Unexplained Phenomena}

This framework predicts the existence of phenomenal states that may be rare or difficult to report on.

\begin{conjecture}[High Rank, Low Integration]
States with many active degrees of freedom ($\effrank$ high) but poor coupling ($\intinfo$ low) should feel like fragmentation, multiplicity, ``everything happening but nothing cohering.''

\textbf{Where to look}: Certain psychedelic states before reintegration; dissociative transitions; information overload.
\end{conjecture}

\begin{conjecture}[Negative Valence, High Rank, Low Arousal]
This combination predicts a state of ``expansive despair''---calm hopelessness with full awareness of possibilities, all of which are negative.

\textbf{Where to look}: Late-stage depression; existential nihilism; certain contemplative ``dark night'' states.
\end{conjecture}

\begin{conjecture}[Rank Exhaustion]
Maintaining high $\effrank$ should be metabolically expensive. Prolonged high-rank states should lead to specific fatigue distinct from physical tiredness.

\textbf{Where to look}: Post-psychedelic fatigue; meditation retreat collapse (days 3-5); therapist burnout.
\end{conjecture}

\begin{conjecture}[Integration Debt]
Suppressing integration (compartmentalizing, dissociating) should accumulate ``pressure'' for reintegration. When defenses fail, the flood should exceed what the original stimulus would warrant.

\textbf{Prediction}: Intensity of breakthrough $\propto$ duration $\times$ degree of prior suppression.
\end{conjecture}

\subsection{Quantitative Predictions}

\begin{proposition}[Clustering Prediction]
In controlled affect induction paradigms, affects should cluster by their defining dimensions:
\begin{enumerate}
\item Joy conditions cluster in the $(+\valence, +\effrank, +\intinfo, -\mathcal{SM})$ region
\item Suffering conditions cluster in the $(-\valence, +\intinfo, -\effrank)$ region
\item Fear and curiosity both show high $\mathcal{CF}$ but separate on valence axis
\end{enumerate}
\textbf{Falsification criterion}: If affects don't cluster by their predicted dimensions---or if other dimensions predict clustering better---the motif characterizations require revision.
\end{proposition}

%==============================================================================
\section{Operational Measurement}
%==============================================================================

\subsection{In Silico Protocol}

For artificial agents (world-model RL agents):

\begin{algorithm}
\caption{Affect Measurement in World-Model Agents}
\begin{algorithmic}[1]
\State \textbf{Agent}: Recurrent latent world model (RSSM, Transformer, etc.)
\State \textbf{Record}: $\latent_t$, policy logits, value estimates, rollout trees, uncertainty
\For{each timestep $t$}
    \State $\valence_t \gets \E[A^\policy(\latent_t, \action_t)]$
    \State $\arousal_t \gets \KL(\latent_{t+1} \| \latent_t)$
    \State $\intinfo_t \gets \Delta_P$ (prediction loss under partition)
    \State $\effrank_t \gets (\tr C_t)^2 / \tr(C_t^2)$
    \State $\mathcal{CF}_t \gets$ rollout compute fraction
    \State $\mathcal{SM}_t \gets \MI(\latent^{\text{self}}_t; \action_t) / \entropy(\action_t)$
\EndFor
\State \textbf{Output}: Time series $\{(\valence_t, \arousal_t, \intinfo_t, \effrank_t, \mathcal{CF}_t, \mathcal{SM}_t)\}$
\end{algorithmic}
\end{algorithm}

\subsection{Biological Protocol}

For neural recordings (MEG/EEG/fMRI):

\begin{itemize}
\item $\intinfo$: Directed influence density (transfer entropy), synergy measures
\item $\effrank$: Participation ratio of neural state covariance
\item $\arousal$: Entropy rate, broadband power shifts, peripheral correlates (pupil, HRV)
\item $\valence$: Approach/avoid behavioral bias, reward prediction error correlates
\item $\mathcal{CF}$: Prefrontal/default mode engagement patterns
\item $\mathcal{SM}$: Self-referential network activation
\end{itemize}

%==============================================================================
\section{Summary of Part II}
%==============================================================================

\begin{enumerate}
\item \textbf{Hard problem dissolved}: By rejecting the privileged base layer, I've removed the demand for reduction. Experience is real at the experiential scale, just as chemistry is real at the chemical scale.

\item \textbf{Identity thesis}: Experience \textit{is} intrinsic cause-effect structure. This is an identity claim, not a correlation.

\item \textbf{Geometric phenomenology}: Different affects correspond to different structural motifs. Rather than forcing all affects into a fixed grid, we identify the defining dimensions for each---the features without which that affect would not be that affect.

\item \textbf{Variable dimensionality}: Joy requires four dimensions (valence, integration, rank, self-salience). Suffering requires three (valence, integration, rank). Anger requires a feature (other-model compression) not in the standard toolkit. I invoke what does the work.

\item \textbf{Suffering explained}: High integration + low rank = intense but trapped. This is the core structural insight---why suffering feels more real than neutral states yet also inescapable.

\item \textbf{Operational measures}: I've provided protocols for measuring structural features in both artificial and biological systems, with the understanding that not all measures are relevant to all phenomena.
\end{enumerate}

In Part III, I'll examine how human cultural forms---aesthetics, sexuality, ideology, science, religion---serve as technologies for managing the existential burden of inescapable selfhood.

In Part IV, I'll develop:
\begin{itemize}
\item The grounding of normativity in viability structure
\item Scale-matched interventions from neurons to nations
\item Gods as agentic systems with viability manifolds
\item Implications for AI systems and alignment
\end{itemize}

And in Part V, I'll address the transcendence of the self: the historical rise of consciousness, the AI frontier, and how to surf rather than be submerged by the coming wave.

